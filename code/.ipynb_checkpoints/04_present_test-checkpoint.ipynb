{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f3ad22",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6724b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889d068",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dd4af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../assets/new_rating.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m movie \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../assets/movie.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rating \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../assets/new_rating.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    186\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../assets/new_rating.pkl'"
     ]
    }
   ],
   "source": [
    "movie = pd.read_pickle('../assets/movie.pkl')\n",
    "rating = pd.read_pickle('../assets/new_rating.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2e87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_rows = 3000000\n",
    "new_rating = rating.sample(num_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9148f72",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289d1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutoff(data, target):\n",
    "    \n",
    "    \"\"\"This function will identify summary statistics from our dataset.\n",
    "    Input:  \n",
    "    data (dataframe): the original dataframe\n",
    "    target (str): a column that we want to get the summary statistics\n",
    "    Output:\n",
    "    summaries (tuple): contains 25% and 75% from the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # check if the values under the target are int/float\n",
    "    \n",
    "    value_type = data[target].dtypes\n",
    "    if value_type == 'O':\n",
    "        print(f\"{target}'s data type is not int or float. Please check it again.'\")\n",
    "\n",
    "    \n",
    "    # get the summary stats\n",
    "    summary_stats = data[target].describe()\n",
    "    \n",
    "    low = summary_stats['25%']\n",
    "    high = summary_stats['75%']\n",
    "    \n",
    "    # combine the results as tuple\n",
    "    summaries = (low, high)\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7490cc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoonhokim/mambaforge/envs/lightfm/lib/python3.9/site-packages/pandas/core/reshape/reshape.py:134: PerformanceWarning: The following operation may generate 3308581738 cells in the resulting pandas object.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_movie_interaction = pd.pivot_table(new_rating, \n",
    "                                        index = 'userId', \n",
    "                                        columns='movieId', \n",
    "                                        values='rating')\n",
    "user_movie_interaction.fillna(0,inplace=True)\n",
    "user_movie_csr = csr_matrix(user_movie_interaction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf795e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = user_movie_interaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83e0462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_features(item_df, user_df):\n",
    "    \n",
    "    # select features from the dataset\n",
    "    item_features = ['clean_movie_title', 'new_genres']\n",
    "    item_df = item_df[item_features]\n",
    "\n",
    "    user_features = ['movieId', 'rating', 'movie_popularities', 'groupped_year']\n",
    "    user_df = user_df[user_features]\n",
    "    \n",
    "    # create a list to store the results\n",
    "    user_data = []\n",
    "    \n",
    "    # unique user in the dataset\n",
    "    unique_user = list(set(user_df.index))\n",
    "    unique_genre = sorted(set(map(lambda genre: \\\n",
    "                                  genre.strip(),','.join(map(lambda genre: str(genre), item_df['new_genres'].values))\\\n",
    "                                  .split(','))))[:-1]\n",
    "    \n",
    "    # get user specific information\n",
    "    for user in unique_user:\n",
    "        user_specific_df = user_df[user_df.index == user]\n",
    "        total_reviews = len(user_specific_df)\n",
    "        genres = item_df.loc[user_specific_df['movieId']]['new_genres'].values\n",
    "        user_genre_list = list(genres)\n",
    "        user_genre_list_split = (','.join(map(lambda genre: str(genre), user_genre_list))).split(',')\n",
    "        \n",
    "        user_genre_score = {}\n",
    "        \n",
    "        # normalize the score\n",
    "        for genre in unique_genre:\n",
    "            user_genre_score[genre] = user_genre_list_split.count(genre)/total_reviews\n",
    "    \n",
    "        user_data.append([user, user_genre_score])\n",
    "    \n",
    "    return user_data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8825d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_metadata = movie.set_index('movieId')\n",
    "user_metadata = new_rating.set_index('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c0d6e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_feats = get_user_features(movie_metadata, user_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b37b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genre = sorted(set(map(lambda genre: \\\n",
    "                                  genre.strip(),','.join(map(lambda genre: str(genre), movie['new_genres'].values))\\\n",
    "                                  .split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ab3c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(user_identity_features = False)\n",
    "dataset.fit(new_rating.sort_values(by = 'userId')['userId'].unique(),\n",
    "            new_rating.sort_values(by = 'movieId')['movieId'].unique(),\n",
    "            user_features = unique_genre,\n",
    "            item_features = [\"Name\"])\n",
    "user_features = dataset.build_user_features(user_feats,\n",
    "                                            normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f052d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:55<00:00, 11.54s/it]\n"
     ]
    }
   ],
   "source": [
    "model_hybrid = LightFM(loss='warp')\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    model_hybrid.fit(user_movie_csr, \n",
    "                     user_features=user_features,\n",
    "                     epochs= 10, \n",
    "                     num_threads= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "518b2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = new_rating.sort_values(by = 'userId')['userId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5b90f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top5(model, movie, dataset, user_id=None, new_user_feature=None, k=5):\n",
    "    \n",
    "    nmovie=movie.set_index('movieId')\n",
    "    \n",
    "    max_user_id = max(rating.userId)\n",
    "    if user_id is None:\n",
    "        user_id = max_user_id +1\n",
    "    if user_id > max_user_id:\n",
    "        for genre in unique_genre:\n",
    "            if genre not in list(new_user_feature.keys()):\n",
    "                new_user_feature[genre] = 0\n",
    "        dataset.fit_partial(users=[user_id],user_features=unique_genre)\n",
    "        new_user_feature = [user_id,new_user_feature]\n",
    "        new_user_feature = dataset.build_user_features([new_user_feature],normalize=False)\n",
    "\n",
    "    user_id_map = dataset.mapping()[0][user_id] \n",
    "    scores = model.predict(user_id_map, np.arange(n_items),user_features=new_user_feature)\n",
    "    rank = np.argsort(-scores)\n",
    "    selected_movie_id =np.array(list(dataset.mapping()[2].keys()))[rank]\n",
    "    top_items = nmovie.loc[selected_movie_id]\n",
    "\n",
    "        \n",
    "    return top_items['clean_movie_title'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068fb334",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be229c8d",
   "metadata": {},
   "source": [
    "change a bit so that we can see what they've watched and their recommended movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9feb852d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "77561              Iron Man 2\n",
       "89745           Avengers, The\n",
       "6365     Matrix Reloaded, The\n",
       "2571              Matrix, The\n",
       "72998                  Avatar\n",
       "Name: clean_movie_title, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_top5(model_hybrid,\n",
    "            movie,\n",
    "            dataset,\n",
    "            user_id = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5737dc3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "2918           Ferris Bueller's Day Off\n",
       "223                              Clerks\n",
       "141                       Birdcage, The\n",
       "344          Ace Ventura: Pet Detective\n",
       "231     Dumb & Dumber (Dumb and Dumber)\n",
       "Name: clean_movie_title, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_top5(model_hybrid,\n",
    "            movie,\n",
    "            dataset,\n",
    "            user_id = None,\n",
    "            new_user_feature= {'Comedy':1, 'Mystery': 0.5, 'Adventure':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4410ca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "2918           Ferris Bueller's Day Off\n",
       "231     Dumb & Dumber (Dumb and Dumber)\n",
       "380                           True Lies\n",
       "223                              Clerks\n",
       "1197                Princess Bride, The\n",
       "Name: clean_movie_title, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_top5(model_hybrid,\n",
    "            movie,\n",
    "            dataset,\n",
    "            user_id = None,\n",
    "            new_user_feature= {'Comedy':0.6, 'Mystery': 0.5, 'Adventure':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bce99656",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_user_info = {}\n",
    "\n",
    "for genre in unique_genre:\n",
    "    rand_score = round(np.random.rand(1)[0], 4)\n",
    "    rand_user_info[genre] = rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bd902b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "364           Lion King, The\n",
       "68954                     Up\n",
       "51662                    300\n",
       "116797    The Imitation Game\n",
       "115210                  Fury\n",
       "Name: clean_movie_title, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_top5(model_hybrid,\n",
    "            movie,\n",
    "            dataset,\n",
    "            user_id = None,\n",
    "            new_user_feature= rand_user_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
